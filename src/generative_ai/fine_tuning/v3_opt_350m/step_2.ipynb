{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pathlib\n",
                "import shutil\n",
                "\n",
                "import numpy\n",
                "from datasets import load_from_disk\n",
                "from evaluate import load\n",
                "from peft import LoraConfig, PeftType, TaskType\n",
                "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, precision_score, recall_score\n",
                "from torch import Tensor, float16\n",
                "from transformers import (\n",
                "    AutoModelForCausalLM,\n",
                "    AutoTokenizer,\n",
                "    BitsAndBytesConfig,\n",
                "    EarlyStoppingCallback,\n",
                "    EvalPrediction,\n",
                "    SchedulerType,\n",
                "    TrainingArguments,\n",
                ")\n",
                "from trl import DataCollatorForCompletionOnlyLM, SFTTrainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "step_identifier = pathlib.Path(\"step_2\")\n",
                "\n",
                "input_directory = pathlib.Path(step_identifier, \"input_directory\")\n",
                "working_directory = pathlib.Path(step_identifier, \"working_directory\")\n",
                "output_directory = pathlib.Path(step_identifier, \"output_directory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hugging_face_dataset_archive = pathlib.Path(input_directory, \"hugging_face_dataset_archive.zip\")\n",
                "hugging_face_dataset_path = pathlib.Path(working_directory, \"hugging_face_dataset_directory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "shutil.unpack_archive(hugging_face_dataset_archive, extract_dir=working_directory)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hugging_face_dataset = load_from_disk(hugging_face_dataset_path)\n",
                "\n",
                "train_subset = hugging_face_dataset[\"train\"]\n",
                "validation_subset = hugging_face_dataset[\"validation\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_model_identifier = \"facebook/opt-350m\"\n",
                "\n",
                "quantisation_configuration = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_compute_dtype=float16,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    bnb_4bit_use_double_quant=True,\n",
                ")\n",
                "\n",
                "mask_token_index = -100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tuning_checkpoints_path = pathlib.Path(working_directory, \"tuning_checkpoints_directory\")\n",
                "tuning_checkpoints_archive = pathlib.Path(output_directory, \"tuning_checkpoints_archive.zip\")\n",
                "\n",
                "tuned_adapter_path = pathlib.Path(working_directory, \"tuned_adapter_directory\")\n",
                "tuned_adapter_archive = pathlib.Path(output_directory, \"tuned_adapter_archive.zip\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    base_model_identifier,\n",
                "    quantization_config=quantisation_configuration,\n",
                "    device_map=\"auto\",\n",
                "    low_cpu_mem_usage=True,\n",
                ")\n",
                "\n",
                "model.config.use_cache = False\n",
                "model.config.pretraining_tp = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokeniser = AutoTokenizer.from_pretrained(base_model_identifier)\n",
                "\n",
                "tokeniser.pad_token = tokeniser.eos_token\n",
                "tokeniser.padding_side = \"right\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "peft_configuration = LoraConfig(\n",
                "    peft_type=PeftType.LORA,\n",
                "    task_type=TaskType.CAUSAL_LM,\n",
                "    r=8,\n",
                "    lora_alpha=16,\n",
                "    lora_dropout=0.1,\n",
                "    bias=\"none\",\n",
                "    use_rslora=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "training_configuration = TrainingArguments(\n",
                "    output_dir=str(tuning_checkpoints_path),\n",
                "    overwrite_output_dir=True,\n",
                "    evaluation_strategy=\"epoch\",\n",
                "    gradient_accumulation_steps=1,\n",
                "    eval_delay=3,\n",
                "    learning_rate=1e-4,\n",
                "    weight_decay=0.001,\n",
                "    max_grad_norm=0.3,\n",
                "    num_train_epochs=50,\n",
                "    lr_scheduler_type=SchedulerType.REDUCE_ON_PLATEAU,\n",
                "    warmup_ratio=0.03,\n",
                "    log_level=\"error\",\n",
                "    logging_strategy=\"epoch\",\n",
                "    save_strategy=\"epoch\",\n",
                "    save_total_limit=5,\n",
                "    save_safetensors=True,\n",
                "    save_only_model=True,\n",
                "    use_cpu=False,\n",
                "    seed=0,\n",
                "    data_seed=0,\n",
                "    fp16=True,\n",
                "    half_precision_backend=\"auto\",\n",
                "    fp16_full_eval=False,\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=\"eval_google_bleu\",\n",
                "    greater_is_better=True,\n",
                "    optim=\"paged_adamw_32bit\",\n",
                "    group_by_length=True,\n",
                "    report_to=[\"none\"],\n",
                "    skip_memory_metrics=True,\n",
                "    push_to_hub=False,\n",
                "    auto_find_batch_size=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "context_template = \" ### Context:\"\n",
                "question_template = \" ### Question:\"\n",
                "answer_template = \" ### Answer:\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_inputs(examples: list[dict[str, str]]) -> list[str]:\n",
                "    return [\n",
                "        \"\\n\".join(\n",
                "            [\n",
                "                f\"{context_template} {examples['context'][counter]}\",\n",
                "                f\"{question_template} {examples['question'][counter]}\",\n",
                "                f\"{answer_template} {examples['answer'][counter]}\",\n",
                "            ]\n",
                "        )\n",
                "        for counter in range(len(examples))\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response_template_with_context = f\"\\n{answer_template}\"\n",
                "response_template_token_indices = tokeniser.encode(\n",
                "    response_template_with_context, add_special_tokens=False\n",
                ")[2:]\n",
                "\n",
                "collator = DataCollatorForCompletionOnlyLM(\n",
                "    response_template_token_indices, tokenizer=tokeniser, ignore_index=mask_token_index\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bleu_metric = load(\"bleu\", module_type=\"metric\")\n",
                "google_bleu_metric = load(\"google_bleu\", module_type=\"metric\")\n",
                "rouge_metric = load(\"rouge\", module_type=\"metric\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_positions_of_most_likely_token(logits: Tensor, labels: Tensor | None) -> Tensor:\n",
                "    del labels\n",
                "\n",
                "    if isinstance(logits, tuple):\n",
                "        logits = logits[0]\n",
                "\n",
                "    return logits.argmax(dim=-1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_multi_class_classification_metrics(\n",
                "    y_true: numpy.ndarray, y_pred: numpy.ndarray\n",
                ") -> dict[str, float]:\n",
                "    accuracy = accuracy_score(y_true, y_pred, normalize=False)\n",
                "\n",
                "    precision = precision_score(y_true, y_pred, average=\"micro\", zero_division=1)\n",
                "    recall = recall_score(y_true, y_pred, average=\"micro\", zero_division=1)\n",
                "\n",
                "    f1_balanced = f1_score(y_true, y_pred, average=\"micro\", zero_division=1)\n",
                "    f1_precision = fbeta_score(y_true, y_pred, beta=0.5, average=\"micro\", zero_division=1)\n",
                "    f1_recall = fbeta_score(y_true, y_pred, beta=2, average=\"micro\", zero_division=1)\n",
                "\n",
                "    return {\n",
                "        \"accuracy\": accuracy,\n",
                "        \"precision\": precision,\n",
                "        \"recall\": recall,\n",
                "        \"f1_balanced\": f1_balanced,\n",
                "        \"f1_precision\": f1_precision,\n",
                "        \"f1_recall\": f1_recall,\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def track_validation_metrics(validation_outputs: EvalPrediction) -> dict[str, float]:\n",
                "    predictions = validation_outputs.predictions\n",
                "    labels = validation_outputs.label_ids\n",
                "\n",
                "    if isinstance(predictions, tuple):\n",
                "        predictions = predictions[0]\n",
                "\n",
                "    predictions = numpy.where(predictions != mask_token_index, predictions, tokeniser.pad_token_id)\n",
                "    labels = numpy.where(labels != mask_token_index, labels, tokeniser.pad_token_id)\n",
                "\n",
                "    decoded_predictions = tokeniser.batch_decode(predictions, skip_special_tokens=True)\n",
                "    decoded_labels = tokeniser.batch_decode(labels, skip_special_tokens=True)\n",
                "\n",
                "    bleu_score = bleu_metric.compute(predictions=decoded_predictions, references=decoded_labels)\n",
                "    google_bleu_score = google_bleu_metric.compute(\n",
                "        predictions=decoded_predictions, references=decoded_labels\n",
                "    )\n",
                "    rouge_score = rouge_metric.compute(predictions=decoded_predictions, references=decoded_labels)\n",
                "\n",
                "    classification_scores = calculate_multi_class_classification_metrics(\n",
                "        labels.flatten(), predictions.flatten()\n",
                "    )\n",
                "\n",
                "    return {**bleu_score, **google_bleu_score, **rouge_score, **classification_scores}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "early_stopping_callback = EarlyStoppingCallback(\n",
                "    early_stopping_patience=10, early_stopping_threshold=0.000001\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "supervised_trainer = SFTTrainer(\n",
                "    model=model,\n",
                "    args=training_configuration,\n",
                "    data_collator=collator,\n",
                "    train_dataset=train_subset,\n",
                "    eval_dataset=validation_subset,\n",
                "    tokenizer=tokeniser,\n",
                "    compute_metrics=track_validation_metrics,\n",
                "    callbacks=[early_stopping_callback],\n",
                "    preprocess_logits_for_metrics=get_positions_of_most_likely_token,\n",
                "    peft_config=peft_configuration,\n",
                "    formatting_func=format_inputs,\n",
                "    packing=False,\n",
                "    max_seq_length=512,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "supervised_trainer.train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "supervised_trainer.model.save_pretrained(tuned_adapter_path, safe_serialization=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_ = shutil.make_archive(\n",
                "    str(pathlib.Path(tuned_adapter_archive.parent, tuned_adapter_archive.stem)),\n",
                "    tuned_adapter_archive.suffix[1:],\n",
                "    root_dir=working_directory,\n",
                "    base_dir=tuned_adapter_path.stem,\n",
                ")\n",
                "\n",
                "_ = shutil.make_archive(\n",
                "    str(pathlib.Path(tuning_checkpoints_archive.parent, tuning_checkpoints_archive.stem)),\n",
                "    tuning_checkpoints_archive.suffix[1:],\n",
                "    root_dir=working_directory,\n",
                "    base_dir=tuning_checkpoints_path.stem,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "genai",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
